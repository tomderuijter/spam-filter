{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "all\n",
      "data loaded\n",
      "11314 documents - 22.055MB (training set)\n",
      "7532 documents - 13.801MB (test set)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "categories = None\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 2.946253s at 7.486MB/s\n",
      "n_samples: 11314, n_features: 65536\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 1.917940s at 7.196MB/s\n",
      "n_samples: 7532, n_features: 65536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "\n",
    "vectorizer = HashingVectorizer(\n",
    "    stop_words='english', non_negative=True,\n",
    "    n_features=2**16\n",
    ")\n",
    "X_train = vectorizer.transform(data_train.data)\n",
    "\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "feature_names = None\n",
    "\n",
    "# print(\"Extracting %d best features by a chi-squared test\" % opts.select_chi2)\n",
    "# t0 = time()\n",
    "# ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "# X_train = ch2.fit_transform(X_train, y_train)\n",
    "# X_test = ch2.transform(X_test)\n",
    "    \n",
    "# print(\"done in %fs\" % (time() - t0))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=target_names))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "    print()\n",
    "    \n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomdr/VirtualEnvs/work-py3/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:311: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 6.754s\n",
      "test time:  0.029s\n",
      "accuracy:   0.837\n",
      "dimensionality: 65536\n",
      "density: 0.859970\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.76      0.77       319\n",
      "           comp.graphics       0.73      0.78      0.76       389\n",
      " comp.os.ms-windows.misc       0.73      0.74      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.76      0.73       392\n",
      "   comp.sys.mac.hardware       0.81      0.84      0.82       385\n",
      "          comp.windows.x       0.87      0.73      0.80       395\n",
      "            misc.forsale       0.83      0.89      0.86       390\n",
      "               rec.autos       0.91      0.90      0.91       396\n",
      "         rec.motorcycles       0.96      0.94      0.95       398\n",
      "      rec.sport.baseball       0.88      0.93      0.91       397\n",
      "        rec.sport.hockey       0.93      0.96      0.95       399\n",
      "               sci.crypt       0.94      0.93      0.94       396\n",
      "         sci.electronics       0.77      0.77      0.77       393\n",
      "                 sci.med       0.90      0.84      0.87       396\n",
      "               sci.space       0.90      0.92      0.91       394\n",
      "  soc.religion.christian       0.81      0.94      0.87       398\n",
      "      talk.politics.guns       0.73      0.90      0.81       364\n",
      "   talk.politics.mideast       0.96      0.87      0.91       376\n",
      "      talk.politics.misc       0.82      0.60      0.70       310\n",
      "      talk.religion.misc       0.74      0.56      0.64       251\n",
      "\n",
      "             avg / total       0.84      0.84      0.84      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[243   2   0   1   1   0   2   0   1   2   0   1   1   7   5  30   1   0\n",
      "    1  21]\n",
      " [  1 305  14   8   7  18   4   1   0   6   2   3   9   1   4   2   1   1\n",
      "    0   2]\n",
      " [  0  17 293  39  14   9   1   2   1   4   1   1   5   0   3   1   0   0\n",
      "    0   3]\n",
      " [  0  12  23 297  16   2  12   1   0   3   0   0  22   0   1   0   0   1\n",
      "    0   2]\n",
      " [  0   5   8  21 322   2  11   1   0   2   2   1   8   0   0   0   2   0\n",
      "    0   0]\n",
      " [  1  39  41   4   6 289   2   0   1   1   0   0   3   2   4   0   1   0\n",
      "    1   0]\n",
      " [  0   1   1  12   7   0 349   6   2   2   1   1   6   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   1   3   1   1   9 357   5   1   0   0  12   1   0   0   1   0\n",
      "    2   0]\n",
      " [  0   0   1   2   0   0   3  10 376   2   0   0   3   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   1   0   2   0   4   1   1 368  18   0   0   0   0   0   1   0\n",
      "    1   0]\n",
      " [  1   1   0   0   4   0   2   0   0   5 383   1   0   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1   1   2   3   4   1   2   1   0 369   3   0   1   1   3   0\n",
      "    3   0]\n",
      " [  3   8   7  26   9   1   4   5   1   5   2   7 303   5   2   1   1   1\n",
      "    2   0]\n",
      " [  3   7   2   3   2   3   7   2   1   4   0   1   9 331   2   4   1   4\n",
      "    6   4]\n",
      " [  1   8   0   0   3   0   2   1   0   1   0   0   7   6 361   0   1   0\n",
      "    2   1]\n",
      " [  5   1   2   1   0   0   0   0   1   2   0   0   3   0   3 373   0   0\n",
      "    0   7]\n",
      " [  0   1   2   2   1   0   3   1   0   1   0   5   0   3   1   2 327   2\n",
      "    9   4]\n",
      " [ 17   1   0   0   0   3   0   1   0   5   1   0   2   2   3   5   2 327\n",
      "    7   0]\n",
      " [  5   1   0   0   2   1   0   1   1   1   0   3   0   2   4   1  93   4\n",
      "  187   4]\n",
      " [ 34   4   2   1   0   0   2   0   0   0   0   0   0   3   4  39  13   2\n",
      "    6 141]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 3.519s\n",
      "test time:  0.027s\n",
      "accuracy:   0.781\n",
      "dimensionality: 65536\n",
      "density: 0.222552\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.70      0.73      0.72       319\n",
      "           comp.graphics       0.70      0.68      0.69       389\n",
      " comp.os.ms-windows.misc       0.71      0.67      0.69       394\n",
      "comp.sys.ibm.pc.hardware       0.75      0.65      0.70       392\n",
      "   comp.sys.mac.hardware       0.71      0.77      0.74       385\n",
      "          comp.windows.x       0.80      0.70      0.74       395\n",
      "            misc.forsale       0.78      0.84      0.81       390\n",
      "               rec.autos       0.75      0.88      0.81       396\n",
      "         rec.motorcycles       0.91      0.91      0.91       398\n",
      "      rec.sport.baseball       0.90      0.85      0.87       397\n",
      "        rec.sport.hockey       0.90      0.93      0.91       399\n",
      "               sci.crypt       0.78      0.90      0.84       396\n",
      "         sci.electronics       0.74      0.60      0.66       393\n",
      "                 sci.med       0.81      0.77      0.79       396\n",
      "               sci.space       0.85      0.90      0.87       394\n",
      "  soc.religion.christian       0.78      0.87      0.82       398\n",
      "      talk.politics.guns       0.74      0.82      0.78       364\n",
      "   talk.politics.mideast       0.84      0.85      0.84       376\n",
      "      talk.politics.misc       0.76      0.58      0.65       310\n",
      "      talk.religion.misc       0.63      0.59      0.61       251\n",
      "\n",
      "             avg / total       0.78      0.78      0.78      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[234   1   0   0   2   1   1   2   1   1   0   6   0   6   5  24   1   6\n",
      "    2  26]\n",
      " [  2 263  13   7  11  19   6   7   3   3   1  15   8   2   6   7   3   7\n",
      "    2   4]\n",
      " [  2  16 264  32  14  13   6   7   1   1   2   8   6   2   2   1   0   4\n",
      "    5   8]\n",
      " [  1  13  24 255  26   5  21   4   4   3   0   2  22   4   1   0   2   1\n",
      "    3   1]\n",
      " [  4   7   2  14 295   7  11   7   1   2   0   2  15   5   2   3   6   1\n",
      "    1   0]\n",
      " [  1  29  42   5   8 276   3   4   2   2   1   6   1   4   3   0   3   3\n",
      "    1   1]\n",
      " [  0   3   3   7  14   1 328  10   3   1   2   3   6   3   1   1   1   2\n",
      "    0   1]\n",
      " [  0   2   0   0   3   0  12 348   5   3   0   5   6   4   0   2   1   1\n",
      "    2   2]\n",
      " [  0   0   0   1   1   0   4  16 362   2   0   2   1   3   0   2   1   1\n",
      "    1   1]\n",
      " [  3   0   0   1   5   1   4   9   0 338  20   1   1   3   4   2   2   0\n",
      "    2   1]\n",
      " [  0   0   1   0   4   3   3   0   1   3 370   3   0   2   3   0   0   4\n",
      "    2   0]\n",
      " [  0   3   2   0   2   2   5   3   1   0   2 358   2   2   1   2   3   2\n",
      "    6   0]\n",
      " [  5  16  13  12  17   8  12  15   5   3   0  18 236   8  11   5   1   6\n",
      "    1   1]\n",
      " [  8   5   4   2   4   4   0  14   1   6   1   3   9 306   3   2   2  10\n",
      "    6   6]\n",
      " [  2  10   0   0   2   1   2   2   0   0   0   1   4   8 355   2   1   1\n",
      "    2   1]\n",
      " [ 13   2   3   1   0   0   0   2   0   1   1   0   1   1   5 345   0   1\n",
      "    1  21]\n",
      " [  3   1   1   1   3   1   2   4   2   2   1  12   1   5   2   3 300   1\n",
      "   14   5]\n",
      " [ 14   3   0   0   0   1   0   4   1   4   4   3   0   1   5   6   2 320\n",
      "    6   2]\n",
      " [  4   0   0   1   1   2   0   6   5   1   2   8   1   9   7   5  63  10\n",
      "  179   6]\n",
      " [ 36   2   1   1   1   1   3   1   0   1   4   1   0   1   3  33  12   2\n",
      "    1 147]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 4.743s\n",
      "test time:  0.037s\n",
      "accuracy:   0.820\n",
      "dimensionality: 65536\n",
      "density: 0.587424\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.76      0.76      0.76       319\n",
      "           comp.graphics       0.74      0.75      0.75       389\n",
      " comp.os.ms-windows.misc       0.72      0.69      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.65      0.71      0.68       392\n",
      "   comp.sys.mac.hardware       0.78      0.82      0.80       385\n",
      "          comp.windows.x       0.85      0.74      0.79       395\n",
      "            misc.forsale       0.82      0.85      0.84       390\n",
      "               rec.autos       0.89      0.88      0.88       396\n",
      "         rec.motorcycles       0.95      0.94      0.94       398\n",
      "      rec.sport.baseball       0.87      0.91      0.89       397\n",
      "        rec.sport.hockey       0.92      0.95      0.94       399\n",
      "               sci.crypt       0.91      0.92      0.92       396\n",
      "         sci.electronics       0.74      0.70      0.72       393\n",
      "                 sci.med       0.85      0.83      0.84       396\n",
      "               sci.space       0.90      0.93      0.91       394\n",
      "  soc.religion.christian       0.85      0.92      0.88       398\n",
      "      talk.politics.guns       0.73      0.88      0.80       364\n",
      "   talk.politics.mideast       0.96      0.86      0.91       376\n",
      "      talk.politics.misc       0.79      0.59      0.67       310\n",
      "      talk.religion.misc       0.65      0.64      0.65       251\n",
      "\n",
      "             avg / total       0.82      0.82      0.82      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[244   1   0   1   0   1   1   0   1   2   0   1   2   6   7  14   1   3\n",
      "    2  32]\n",
      " [  1 292  13  10   8  19   4   3   0   6   4   8   6   2   4   4   1   1\n",
      "    0   3]\n",
      " [  1  19 272  50  11  13   3   2   1   4   0   3   4   1   3   1   1   0\n",
      "    0   5]\n",
      " [  0   8  22 278  26   3  14   1   0   4   0   2  30   0   1   0   1   0\n",
      "    1   1]\n",
      " [  1   8   4  17 314   3  10   1   0   3   0   0  15   7   0   0   2   0\n",
      "    0   0]\n",
      " [  1  32  39   8   4 294   2   0   1   4   1   0   2   4   2   0   1   0\n",
      "    0   0]\n",
      " [  0   1   2  14  10   1 332   9   4   2   1   1   7   3   1   1   1   0\n",
      "    0   0]\n",
      " [  1   2   2   4   1   1  11 347   5   2   0   2   7   4   0   1   4   0\n",
      "    2   0]\n",
      " [  1   0   1   2   2   0   3   7 374   3   0   0   1   0   1   0   1   0\n",
      "    1   1]\n",
      " [  3   0   0   1   1   0   2   2   0 362  16   1   1   3   0   1   2   0\n",
      "    2   0]\n",
      " [  0   1   0   0   4   1   2   0   2   4 381   1   0   0   0   0   1   0\n",
      "    2   0]\n",
      " [  0   2   1   2   5   2   3   2   1   1   1 366   2   1   0   1   3   0\n",
      "    3   0]\n",
      " [  5   8  13  29  12   2   8   6   1   5   2   6 275   8   6   2   1   1\n",
      "    2   1]\n",
      " [  4   5   2   5   1   3   2   6   1   4   3   0  12 327   2   3   2   2\n",
      "    4   8]\n",
      " [  2   7   0   0   1   1   1   1   0   0   0   0   5   5 365   2   1   0\n",
      "    1   2]\n",
      " [  6   1   2   1   0   0   0   0   1   1   0   0   1   0   2 368   0   0\n",
      "    1  14]\n",
      " [  1   1   2   1   1   1   1   0   1   3   0   6   0   3   0   0 322   2\n",
      "   15   4]\n",
      " [ 17   1   0   0   0   1   0   0   0   3   3   1   3   0   3   9   4 324\n",
      "    7   0]\n",
      " [  3   2   1   1   2   1   1   0   1   1   1   3   1   6   5   4  78   3\n",
      "  182  14]\n",
      " [ 29   1   1   1   0   0   3   2   0   2   0   0   0   3   4  24  13   2\n",
      "    6 160]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.007s\n",
      "test time:  6.095s\n",
      "accuracy:   0.623\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.48      0.71      0.57       319\n",
      "           comp.graphics       0.44      0.53      0.48       389\n",
      " comp.os.ms-windows.misc       0.52      0.61      0.56       394\n",
      "comp.sys.ibm.pc.hardware       0.50      0.55      0.53       392\n",
      "   comp.sys.mac.hardware       0.51      0.50      0.51       385\n",
      "          comp.windows.x       0.64      0.50      0.57       395\n",
      "            misc.forsale       0.50      0.51      0.51       390\n",
      "               rec.autos       0.61      0.64      0.62       396\n",
      "         rec.motorcycles       0.78      0.81      0.79       398\n",
      "      rec.sport.baseball       0.55      0.69      0.62       397\n",
      "        rec.sport.hockey       0.75      0.83      0.79       399\n",
      "               sci.crypt       0.78      0.78      0.78       396\n",
      "         sci.electronics       0.64      0.41      0.50       393\n",
      "                 sci.med       0.65      0.43      0.52       396\n",
      "               sci.space       0.72      0.75      0.74       394\n",
      "  soc.religion.christian       0.79      0.70      0.74       398\n",
      "      talk.politics.guns       0.67      0.70      0.68       364\n",
      "   talk.politics.mideast       0.77      0.71      0.74       376\n",
      "      talk.politics.misc       0.70      0.57      0.63       310\n",
      "      talk.religion.misc       0.55      0.44      0.49       251\n",
      "\n",
      "             avg / total       0.63      0.62      0.62      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[228   3   0   3   1   3   1   1   3   3   1   4   1  12   3  21   3   5\n",
      "    2  21]\n",
      " [  6 206  32  20  21  20   8   9   5  19   2   8   7   4   5   2   5   7\n",
      "    2   1]\n",
      " [  4  30 240  19  15  11  11   4   3  16   9  10   3   3   7   1   3   2\n",
      "    1   2]\n",
      " [  7  22  29 217  23  10  22  13   2   9   2   3  17   0   8   0   0   3\n",
      "    1   4]\n",
      " [  9  10  26  40 193   7  27   8   4  15   6   2   9   4  11   1   1   7\n",
      "    2   3]\n",
      " [  5  56  50  11  16 199   9   3   8  11   2   5   5   1   8   0   0   3\n",
      "    3   0]\n",
      " [  7  18  18  31  27   8 199  18   8  15   6   5  11   4   0   1   4   5\n",
      "    2   3]\n",
      " [ 10  18   6  12  17   9  17 253   9  10   1   4   6   6   5   1   6   1\n",
      "    3   2]\n",
      " [  2   5   1   3   4   2   9  23 321   6   3   2   3   1   1   1   3   3\n",
      "    4   1]\n",
      " [ 12  10   4   2   7   0  14  19   3 274  35   0   1   1   1   0   9   0\n",
      "    4   1]\n",
      " [  3   2   4   3   6   7   8   1   6  15 332   1   2   3   0   0   1   1\n",
      "    0   4]\n",
      " [  6   8   5   3   8   5   2   2   5   3   4 310   0   7   4   0  16   4\n",
      "    4   0]\n",
      " [ 17  24  17  27  11   6  19  17  14  18   6   8 163   8  20   2   3   5\n",
      "    4   4]\n",
      " [ 25   9  17  23  14   6  15  15  11  23   8   3  17 170   6   3   3  10\n",
      "   11   7]\n",
      " [ 12  19   2   4   2   2   8   6   2   9   4   3   4   7 297   3   2   1\n",
      "    7   0]\n",
      " [ 27   4   3   3   2   0   3   3   1  22   8   2   2   4   7 277   0   4\n",
      "    8  18]\n",
      " [  4   7   2   4   2   4   6   6   1  12   1  14   2   9   9   2 255   6\n",
      "    8  10]\n",
      " [ 41   3   1   3   0   7   4   5   4   5   5   2   1   4   4   7   7 267\n",
      "    4   2]\n",
      " [  9   7   1   3   2   2   8   8   1   4   3   8   2   3   7   2  49   6\n",
      "  178   7]\n",
      " [ 43   2   1   2   4   1   6   4   1   5   3   1   0  11   8  25  12   7\n",
      "    5 110]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 38.497s\n",
      "test time:  0.865s\n",
      "accuracy:   0.767\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.74      0.65      0.69       319\n",
      "           comp.graphics       0.64      0.70      0.67       389\n",
      " comp.os.ms-windows.misc       0.67      0.79      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.64      0.68      0.66       392\n",
      "   comp.sys.mac.hardware       0.77      0.78      0.77       385\n",
      "          comp.windows.x       0.77      0.68      0.72       395\n",
      "            misc.forsale       0.75      0.87      0.80       390\n",
      "               rec.autos       0.85      0.81      0.83       396\n",
      "         rec.motorcycles       0.88      0.90      0.89       398\n",
      "      rec.sport.baseball       0.81      0.92      0.86       397\n",
      "        rec.sport.hockey       0.89      0.92      0.91       399\n",
      "               sci.crypt       0.87      0.90      0.89       396\n",
      "         sci.electronics       0.67      0.53      0.59       393\n",
      "                 sci.med       0.83      0.70      0.76       396\n",
      "               sci.space       0.81      0.86      0.83       394\n",
      "  soc.religion.christian       0.70      0.94      0.80       398\n",
      "      talk.politics.guns       0.65      0.83      0.73       364\n",
      "   talk.politics.mideast       0.95      0.79      0.86       376\n",
      "      talk.politics.misc       0.79      0.53      0.63       310\n",
      "      talk.religion.misc       0.74      0.32      0.45       251\n",
      "\n",
      "             avg / total       0.77      0.77      0.76      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[206   3   0   2   3   2   4   0   0   7   1   2   1   7   4  48   2   6\n",
      "    1  20]\n",
      " [  1 273  23  16  12  24   3   4   2   8   0   3   6   1   9   1   2   1\n",
      "    0   0]\n",
      " [  0  20 312  22   9  10   0   4   0   3   2   4   2   0   4   0   0   1\n",
      "    1   0]\n",
      " [  1  22  36 268  16   5   9   4   3   0   2   3  19   1   3   0   0   0\n",
      "    0   0]\n",
      " [  1   4  10  30 299   4  12   1   1   5   1   1  10   2   3   0   0   0\n",
      "    1   0]\n",
      " [  0  36  55   6   7 267   8   1   0   0   0   1   4   0   8   0   1   0\n",
      "    1   0]\n",
      " [  0   4   2  15  11   1 338   3   1   1   0   1   6   2   3   1   1   0\n",
      "    0   0]\n",
      " [  1   6   3   4   0   3  14 322  14   2   1   0   8   2   4   3   8   0\n",
      "    1   0]\n",
      " [  1   0   1   2   2   1   9   9 360   1   0   1   4   4   0   0   3   0\n",
      "    0   0]\n",
      " [  0   3   0   0   0   0   2   0   4 367  16   2   1   1   0   1   0   0\n",
      "    0   0]\n",
      " [  0   3   0   0   2   0   1   0   0  19 369   0   1   0   1   2   0   0\n",
      "    1   0]\n",
      " [  0   1   3   3   1   3   5   1   1   1   0 358   6   1   1   2   6   0\n",
      "    3   0]\n",
      " [  3  18  14  32  17   9  16  17  16   7   5  14 207   1  11   1   4   0\n",
      "    0   1]\n",
      " [  6  12   1   9   4   9  16   4   1  12   2   3  20 276   5   8   2   1\n",
      "    5   0]\n",
      " [  0  15   1   1   4   1   4   2   2   5   3   2   3   6 337   0   3   0\n",
      "    5   0]\n",
      " [  3   1   2   2   0   2   3   0   1   3   0   0   1   2   2 374   0   0\n",
      "    0   2]\n",
      " [  0   1   0   4   1   1   6   2   2   5   0  10   3   5   2   5 302   1\n",
      "   13   1]\n",
      " [ 21   0   0   1   0   3   0   1   0   6   7   4   1   4   2   8  11 297\n",
      "    7   3]\n",
      " [  1   3   0   3   1   0   2   1   0   0   3   2   2   9  12   4 102   1\n",
      "  163   1]\n",
      " [ 32   3   2   2   1   0   1   2   1   2   2   0   3   7   6  76  20   5\n",
      "    5  81]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomdr/VirtualEnvs/work-py3/lib/python3.5/site-packages/sklearn/svm/classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 3.943s\n",
      "test time:  0.016s\n",
      "accuracy:   0.834\n",
      "dimensionality: 65536\n",
      "density: 0.859970\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.77      0.78       319\n",
      "           comp.graphics       0.74      0.79      0.76       389\n",
      " comp.os.ms-windows.misc       0.74      0.72      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.70      0.73      0.71       392\n",
      "   comp.sys.mac.hardware       0.80      0.83      0.81       385\n",
      "          comp.windows.x       0.86      0.74      0.80       395\n",
      "            misc.forsale       0.80      0.89      0.84       390\n",
      "               rec.autos       0.90      0.88      0.89       396\n",
      "         rec.motorcycles       0.95      0.94      0.94       398\n",
      "      rec.sport.baseball       0.89      0.92      0.90       397\n",
      "        rec.sport.hockey       0.93      0.97      0.95       399\n",
      "               sci.crypt       0.94      0.93      0.93       396\n",
      "         sci.electronics       0.74      0.74      0.74       393\n",
      "                 sci.med       0.90      0.84      0.87       396\n",
      "               sci.space       0.90      0.93      0.92       394\n",
      "  soc.religion.christian       0.83      0.94      0.88       398\n",
      "      talk.politics.guns       0.75      0.90      0.82       364\n",
      "   talk.politics.mideast       0.95      0.89      0.92       376\n",
      "      talk.politics.misc       0.82      0.59      0.69       310\n",
      "      talk.religion.misc       0.70      0.60      0.65       251\n",
      "\n",
      "             avg / total       0.84      0.83      0.83      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[245   3   0   1   1   0   2   0   2   1   0   1   1   6   5  22   0   4\n",
      "    1  24]\n",
      " [  1 308  12   6   7  17   4   2   1   5   2   4  12   0   2   2   1   1\n",
      "    0   2]\n",
      " [  0  19 283  41  11  11   2   2   1   5   2   3   4   0   4   0   0   1\n",
      "    0   5]\n",
      " [  0  13  22 286  19   4  16   1   0   3   0   0  27   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   5   3  18 318   2  17   0   0   3   1   0  12   4   0   0   2   0\n",
      "    0   0]\n",
      " [  1  36  39   4   4 292   4   1   0   2   1   0   5   2   3   0   1   0\n",
      "    0   0]\n",
      " [  0   1   2  12   8   0 347   6   1   2   1   1   6   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   2   4   1   1  12 348   8   1   0   1   8   2   1   1   1   0\n",
      "    3   0]\n",
      " [  1   0   1   2   0   0   4   9 373   2   0   0   2   0   0   1   1   0\n",
      "    1   1]\n",
      " [  1   0   0   1   2   1   4   1   0 364  18   0   1   0   0   0   1   1\n",
      "    2   0]\n",
      " [  0   1   0   0   4   1   2   0   1   3 386   0   0   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   2   1   1   3   3   6   2   1   1   0 367   4   0   0   1   2   0\n",
      "    2   0]\n",
      " [  2   9  11  28   9   0   7   5   1   4   1   7 291   5   6   2   1   0\n",
      "    2   2]\n",
      " [  4   6   1   3   3   3   4   2   1   5   1   0  11 334   1   3   2   2\n",
      "    3   7]\n",
      " [  2   7   0   1   2   0   1   1   0   0   0   0   5   4 367   2   0   0\n",
      "    1   1]\n",
      " [  5   1   2   0   0   0   0   0   1   1   0   0   3   0   2 373   0   0\n",
      "    0  10]\n",
      " [  0   1   1   2   1   1   2   1   0   3   0   3   0   4   1   0 328   2\n",
      "   11   3]\n",
      " [ 12   1   0   0   0   2   0   1   0   4   2   0   2   0   3   6   2 334\n",
      "    6   1]\n",
      " [  2   2   0   0   4   0   0   2   2   1   0   3   1   4   5   4  85   3\n",
      "  183   9]\n",
      " [ 32   2   1   1   0   0   2   2   0   1   0   0   0   3   5  30  12   2\n",
      "    7 151]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 3.710s\n",
      "test time:  0.026s\n",
      "accuracy:   0.829\n",
      "dimensionality: 65536\n",
      "density: 0.462469\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.79      0.74      0.77       319\n",
      "           comp.graphics       0.73      0.77      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.73      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.71      0.71       392\n",
      "   comp.sys.mac.hardware       0.81      0.82      0.81       385\n",
      "          comp.windows.x       0.88      0.72      0.79       395\n",
      "            misc.forsale       0.80      0.90      0.85       390\n",
      "               rec.autos       0.89      0.87      0.88       396\n",
      "         rec.motorcycles       0.92      0.94      0.93       398\n",
      "      rec.sport.baseball       0.88      0.91      0.90       397\n",
      "        rec.sport.hockey       0.92      0.97      0.94       399\n",
      "               sci.crypt       0.92      0.94      0.93       396\n",
      "         sci.electronics       0.76      0.73      0.75       393\n",
      "                 sci.med       0.89      0.85      0.87       396\n",
      "               sci.space       0.89      0.93      0.91       394\n",
      "  soc.religion.christian       0.82      0.92      0.87       398\n",
      "      talk.politics.guns       0.73      0.90      0.80       364\n",
      "   talk.politics.mideast       0.94      0.90      0.92       376\n",
      "      talk.politics.misc       0.83      0.60      0.69       310\n",
      "      talk.religion.misc       0.71      0.58      0.64       251\n",
      "\n",
      "             avg / total       0.83      0.83      0.83      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[237   1   0   1   0   0   3   0   3   1   0   2   3   8   6  24   0   6\n",
      "    1  23]\n",
      " [  2 300  14   8   5  18   4   1   3   5   3   7   6   2   5   2   1   1\n",
      "    0   2]\n",
      " [  0  18 286  33  13   8   3   3   2   5   2   3   4   0   4   0   0   1\n",
      "    3   6]\n",
      " [  0  14  27 277  19   4  15   3   0   4   0   1  26   0   0   0   0   0\n",
      "    1   1]\n",
      " [  0   6   6  19 315   1  13   0   0   4   2   1  12   3   0   0   2   0\n",
      "    1   0]\n",
      " [  1  37  40   3   6 286   3   1   0   2   1   1   4   2   5   0   1   2\n",
      "    0   0]\n",
      " [  0   1   2  10   6   0 350   7   1   2   1   1   5   2   1   0   0   1\n",
      "    0   0]\n",
      " [  0   2   2   2   2   0  12 345  10   1   0   1  11   2   0   0   3   0\n",
      "    3   0]\n",
      " [  0   0   1   2   0   0   3  10 375   1   0   0   2   0   1   1   1   0\n",
      "    0   1]\n",
      " [  1   0   0   1   2   1   6   1   1 363  17   0   1   0   0   0   1   1\n",
      "    1   0]\n",
      " [  0   0   0   0   4   1   1   0   0   6 386   0   0   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   1   2   0   2   2   5   2   1   1   0 371   4   0   0   1   2   0\n",
      "    2   0]\n",
      " [  1   9   6  30   9   1   5   5   4   6   2   7 288   5   7   3   2   1\n",
      "    2   0]\n",
      " [  5   8   2   2   1   2   3   1   1   3   2   1   8 335   2   4   3   3\n",
      "    2   8]\n",
      " [  2   7   0   0   2   0   4   1   0   0   0   0   3   4 367   2   0   0\n",
      "    1   1]\n",
      " [  7   1   2   0   0   0   1   0   1   1   0   0   3   1   3 368   0   0\n",
      "    0  10]\n",
      " [  0   1   0   2   1   0   2   1   1   3   2   6   0   2   2   1 327   2\n",
      "    9   2]\n",
      " [  8   1   1   0   0   2   0   1   0   3   3   0   0   1   2   6   3 339\n",
      "    6   0]\n",
      " [  2   1   0   0   2   0   0   2   4   0   0   3   0   4   4   4  91   3\n",
      "  185   5]\n",
      " [ 33   1   2   1   0   0   2   3   0   1   0   0   0   4   5  32  13   2\n",
      "    7 145]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomdr/VirtualEnvs/work-py3/lib/python3.5/site-packages/sklearn/svm/classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 11.551s\n",
      "test time:  0.016s\n",
      "accuracy:   0.799\n",
      "dimensionality: 65536\n",
      "density: 0.005753\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.71      0.73       319\n",
      "           comp.graphics       0.72      0.75      0.73       389\n",
      " comp.os.ms-windows.misc       0.72      0.71      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.71      0.68       392\n",
      "   comp.sys.mac.hardware       0.77      0.80      0.79       385\n",
      "          comp.windows.x       0.84      0.71      0.77       395\n",
      "            misc.forsale       0.80      0.86      0.82       390\n",
      "               rec.autos       0.84      0.86      0.85       396\n",
      "         rec.motorcycles       0.91      0.92      0.91       398\n",
      "      rec.sport.baseball       0.86      0.89      0.87       397\n",
      "        rec.sport.hockey       0.93      0.95      0.94       399\n",
      "               sci.crypt       0.91      0.91      0.91       396\n",
      "         sci.electronics       0.67      0.69      0.68       393\n",
      "                 sci.med       0.84      0.79      0.82       396\n",
      "               sci.space       0.86      0.89      0.87       394\n",
      "  soc.religion.christian       0.82      0.91      0.86       398\n",
      "      talk.politics.guns       0.71      0.84      0.77       364\n",
      "   talk.politics.mideast       0.94      0.79      0.86       376\n",
      "      talk.politics.misc       0.75      0.59      0.66       310\n",
      "      talk.religion.misc       0.62      0.54      0.58       251\n",
      "\n",
      "             avg / total       0.80      0.80      0.80      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[228   1   0   0   3   0   4   0   1   1   1   1   4   7  10  22   0   2\n",
      "    3  31]\n",
      " [  4 293  11   9   7  19   5   2   3   5   1   3  10   3   5   4   0   1\n",
      "    2   2]\n",
      " [  1  23 278  35  13  10   2   4   2   1   2   4   5   5   3   2   0   0\n",
      "    1   3]\n",
      " [  2   7  26 277  23   5  13   4   1   2   0   1  27   2   1   0   0   0\n",
      "    0   1]\n",
      " [  0   5   6  34 309   0   9   0   0   1   0   0  15   3   0   0   2   0\n",
      "    0   1]\n",
      " [  0  41  39   4   5 280   4   0   1   1   1   0   7   2   7   2   0   0\n",
      "    1   0]\n",
      " [  0   2   2  11  10   0 334   8   3   1   1   2   7   3   1   2   0   0\n",
      "    1   2]\n",
      " [  1   4   1   3   1   0   8 342   6   1   0   0  16   3   1   2   4   0\n",
      "    2   1]\n",
      " [  1   1   0   2   1   1   4  10 365   3   0   1   3   1   0   0   1   0\n",
      "    2   2]\n",
      " [  1   0   2   0   0   1   6   3   3 352  14   2   5   2   2   0   2   0\n",
      "    1   1]\n",
      " [  0   1   1   0   4   0   2   0   2   7 378   1   0   0   0   1   0   1\n",
      "    1   0]\n",
      " [  0   3   1   1   3   1   4   2   1   0   0 362   6   1   0   2   5   0\n",
      "    4   0]\n",
      " [  6   8   8  28  16   5  11   9   4   7   1   4 270   6   4   4   0   0\n",
      "    2   0]\n",
      " [  3   6   2   6   1   4   8   4   2   9   1   5   8 313   5   3   2   2\n",
      "    3   9]\n",
      " [  1   8   1   0   3   0   2   3   2   3   0   1   7   8 351   1   1   0\n",
      "    2   0]\n",
      " [  6   1   5   0   0   1   0   0   0   1   0   0   3   1   2 363   0   3\n",
      "    1  11]\n",
      " [  0   1   3   4   1   1   1   2   2   3   0   6   2   4   1   1 306   3\n",
      "   14   9]\n",
      " [ 10   1   0   1   0   5   2   4   1   7   3   2   5   1   8   4   3 298\n",
      "   16   5]\n",
      " [  3   1   0   1   2   2   1   4   2   3   1   1   2   4   6   2  85   2\n",
      "  183   5]\n",
      " [ 39   2   2   1   0   0   0   4   0   2   1   0   2   2   3  28  17   6\n",
      "    6 136]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 9.659s\n",
      "test time:  0.021s\n",
      "accuracy:   0.766\n",
      "dimensionality: 65536\n",
      "density: 0.002617\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.66      0.69       319\n",
      "           comp.graphics       0.69      0.69      0.69       389\n",
      " comp.os.ms-windows.misc       0.68      0.74      0.71       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.65      0.66       392\n",
      "   comp.sys.mac.hardware       0.71      0.75      0.72       385\n",
      "          comp.windows.x       0.77      0.68      0.72       395\n",
      "            misc.forsale       0.79      0.83      0.81       390\n",
      "               rec.autos       0.82      0.80      0.81       396\n",
      "         rec.motorcycles       0.85      0.88      0.87       398\n",
      "      rec.sport.baseball       0.80      0.89      0.84       397\n",
      "        rec.sport.hockey       0.90      0.93      0.91       399\n",
      "               sci.crypt       0.90      0.90      0.90       396\n",
      "         sci.electronics       0.66      0.59      0.62       393\n",
      "                 sci.med       0.79      0.78      0.78       396\n",
      "               sci.space       0.84      0.89      0.86       394\n",
      "  soc.religion.christian       0.77      0.91      0.84       398\n",
      "      talk.politics.guns       0.67      0.83      0.74       364\n",
      "   talk.politics.mideast       0.85      0.78      0.82       376\n",
      "      talk.politics.misc       0.74      0.57      0.65       310\n",
      "      talk.religion.misc       0.56      0.37      0.44       251\n",
      "\n",
      "             avg / total       0.76      0.77      0.76      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[211   1   0   0   6   2   4   0   3   3   3   3   2   8   8  33   2   8\n",
      "    2  20]\n",
      " [  2 270  16  10  15  25   4   3   2   7   1   1   8   4   7   3   1   6\n",
      "    2   2]\n",
      " [  0  17 290  24  14  11   0   1   3   8   2   3   4   4   2   1   0   2\n",
      "    2   6]\n",
      " [  1  12  35 256  22   9  11   2   2   3   1   1  29   2   1   0   2   0\n",
      "    0   3]\n",
      " [  0   4  10  43 287   2  10   1   0   3   1   0  16   0   0   0   1   3\n",
      "    1   3]\n",
      " [  0  42  44   3   8 268   2   2   1   1   1   0   9   4   7   2   0   0\n",
      "    1   0]\n",
      " [  0   4   3  14   8   1 325   7   4   5   3   2   6   2   3   1   1   0\n",
      "    0   1]\n",
      " [  2   5   1   3   3   3  10 315  12   3   1   0  15   6   2   3   8   1\n",
      "    3   0]\n",
      " [  1   1   0   1   3   1   6  14 352   4   0   0   1   4   0   2   4   0\n",
      "    2   2]\n",
      " [  0   0   1   0   1   2   4   1   1 353  17   3   1   3   2   1   1   0\n",
      "    1   5]\n",
      " [  0   1   0   0   7   0   4   0   4   9 370   1   0   0   1   0   0   1\n",
      "    1   0]\n",
      " [  0   1   2   0   6   2   3   0   4   0   0 355   7   4   2   1   6   1\n",
      "    2   0]\n",
      " [  4  11  12  23  23   6   6  12  12  13   4   7 230  10   7   5   3   2\n",
      "    2   1]\n",
      " [  4   9   3   6   0   3   7   5   1   5   0   2   6 308   4   4   4   3\n",
      "    7  15]\n",
      " [  2   9   1   1   3   2   2   2   2   2   1   1   3   7 351   0   0   1\n",
      "    4   0]\n",
      " [ 10   2   2   0   0   3   0   1   1   0   1   0   4   2   1 361   0   1\n",
      "    4   5]\n",
      " [  0   0   3   2   1   1   3   5   4   5   1   9   4   6   2   2 302   4\n",
      "    9   1]\n",
      " [ 12   1   0   0   0   4   2   4   2   9   5   3   1   1  10   5   8 293\n",
      "   11   5]\n",
      " [  3   1   0   0   0   0   2   2   0   2   0   2   2   9   4   2  93   7\n",
      "  178   3]\n",
      " [ 43   2   1   2   0   1   4   6   4   5   1   1   2   5   5  40  18  10\n",
      "    9  92]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 14.420s\n",
      "test time:  0.021s\n",
      "accuracy:   0.817\n",
      "dimensionality: 65536\n",
      "density: 0.043418\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.74      0.74      0.74       319\n",
      "           comp.graphics       0.73      0.74      0.74       389\n",
      " comp.os.ms-windows.misc       0.71      0.72      0.72       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.68      0.70       392\n",
      "   comp.sys.mac.hardware       0.78      0.80      0.79       385\n",
      "          comp.windows.x       0.84      0.73      0.78       395\n",
      "            misc.forsale       0.81      0.89      0.85       390\n",
      "               rec.autos       0.89      0.87      0.88       396\n",
      "         rec.motorcycles       0.92      0.93      0.93       398\n",
      "      rec.sport.baseball       0.87      0.91      0.89       397\n",
      "        rec.sport.hockey       0.91      0.96      0.94       399\n",
      "               sci.crypt       0.92      0.93      0.93       396\n",
      "         sci.electronics       0.73      0.70      0.71       393\n",
      "                 sci.med       0.85      0.84      0.85       396\n",
      "               sci.space       0.87      0.92      0.90       394\n",
      "  soc.religion.christian       0.82      0.92      0.86       398\n",
      "      talk.politics.guns       0.71      0.90      0.79       364\n",
      "   talk.politics.mideast       0.92      0.87      0.89       376\n",
      "      talk.politics.misc       0.80      0.60      0.69       310\n",
      "      talk.religion.misc       0.71      0.52      0.60       251\n",
      "\n",
      "             avg / total       0.82      0.82      0.81      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[235   1   0   0   0   0   3   0   3   3   0   2   3   8   5  27   3   6\n",
      "    2  18]\n",
      " [  3 288  15   6   7  24   4   3   3   4   3   4   8   2   6   3   1   3\n",
      "    1   1]\n",
      " [  0  17 285  29  14   9   2   2   0   9   1   3   4   4   4   1   0   1\n",
      "    2   7]\n",
      " [  1  10  31 266  20   5  17   3   0   2   0   2  29   1   1   0   1   0\n",
      "    0   3]\n",
      " [  0   4   7  22 307   2  13   0   0   6   2   1  13   4   0   0   3   0\n",
      "    0   1]\n",
      " [  1  37  40   3   5 288   3   0   0   0   1   0   5   3   5   1   1   1\n",
      "    1   0]\n",
      " [  0   1   2  11   9   0 347   5   2   1   1   1   6   2   1   0   0   1\n",
      "    0   0]\n",
      " [  0   2   2   1   2   0  11 343   9   1   0   1  15   3   0   0   3   0\n",
      "    3   0]\n",
      " [  1   0   1   1   0   0   3   9 371   3   0   0   3   1   0   0   2   0\n",
      "    2   1]\n",
      " [  0   0   0   1   3   1   5   1   0 362  18   0   1   2   1   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   5   1   2   0   1   5 384   0   0   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   1   1   0   3   3   3   1   1   1   0 370   4   2   0   1   2   1\n",
      "    2   0]\n",
      " [  3  12   7  25  13   1   7   6   5   5   3  10 274   7   9   2   0   1\n",
      "    2   1]\n",
      " [  6   5   2   2   1   2   4   1   1   4   3   0   7 334   3   3   3   5\n",
      "    3   7]\n",
      " [  2   9   0   0   2   0   3   1   0   0   0   1   2   7 364   0   0   0\n",
      "    2   1]\n",
      " [ 10   2   3   0   0   0   0   0   1   1   0   0   3   1   2 366   0   1\n",
      "    1   7]\n",
      " [  0   0   3   2   1   1   1   3   2   3   1   6   0   2   1   1 326   2\n",
      "    7   2]\n",
      " [ 14   1   1   0   0   4   0   1   0   3   4   1   0   1   4   4   2 327\n",
      "    8   1]\n",
      " [  2   1   0   0   1   0   1   3   3   0   1   1   0   4   6   2  93   4\n",
      "  185   3]\n",
      " [ 38   1   1   1   0   0   2   3   0   1   0   0   0   4   5  38  17   2\n",
      "    8 130]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.077s\n",
      "test time:  0.037s\n",
      "accuracy:   0.610\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.62      0.43      0.51       319\n",
      "           comp.graphics       0.47      0.66      0.55       389\n",
      " comp.os.ms-windows.misc       0.73      0.61      0.66       394\n",
      "comp.sys.ibm.pc.hardware       0.61      0.50      0.55       392\n",
      "   comp.sys.mac.hardware       0.63      0.62      0.63       385\n",
      "          comp.windows.x       0.68      0.60      0.64       395\n",
      "            misc.forsale       0.64      0.76      0.70       390\n",
      "               rec.autos       0.87      0.58      0.69       396\n",
      "         rec.motorcycles       0.44      0.75      0.55       398\n",
      "      rec.sport.baseball       0.33      0.69      0.44       397\n",
      "        rec.sport.hockey       0.84      0.70      0.77       399\n",
      "               sci.crypt       0.96      0.66      0.78       396\n",
      "         sci.electronics       0.38      0.53      0.44       393\n",
      "                 sci.med       0.79      0.38      0.52       396\n",
      "               sci.space       0.83      0.68      0.75       394\n",
      "  soc.religion.christian       0.72      0.70      0.71       398\n",
      "      talk.politics.guns       0.69      0.66      0.67       364\n",
      "   talk.politics.mideast       0.98      0.64      0.77       376\n",
      "      talk.politics.misc       0.55      0.55      0.55       310\n",
      "      talk.religion.misc       0.46      0.38      0.42       251\n",
      "\n",
      "             avg / total       0.67      0.61      0.62      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[136  12   0   0   2   1   5   0  15  17   1   1   8   8   2  56   4   2\n",
      "    5  44]\n",
      " [  2 256  14   8  11  28   8   1  12  18   1   1  17   2   5   0   1   0\n",
      "    1   3]\n",
      " [  1  43 240  22  14  19   6   1  17  13   1   0   5   1   1   0   2   0\n",
      "    6   2]\n",
      " [  0  36  23 195  23  10  16   0  16  18   1   1  45   2   2   0   0   0\n",
      "    3   1]\n",
      " [  1   7   5  48 239   4  13   0   9  29   1   0  24   1   3   0   0   0\n",
      "    1   0]\n",
      " [  0  52  36   1  12 238   8   0  10  13   0   2  14   1   7   0   0   0\n",
      "    1   0]\n",
      " [  0   6   2  19  13   5 298   6  11  12   2   0  12   0   1   1   0   0\n",
      "    1   1]\n",
      " [  3   8   0   0   8   1  18 229  34  42   0   0  33   1   5   0   3   0\n",
      "   11   0]\n",
      " [  1   6   0   1   7   1  11   9 297  35   2   0  22   1   1   0   2   0\n",
      "    2   0]\n",
      " [  2   5   0   0   1   6   7   1  45 272  35   0  12   1   0   0   1   0\n",
      "    7   2]\n",
      " [  0   3   0   0   1   3   7   0  24  73 280   0   2   0   2   0   0   0\n",
      "    2   2]\n",
      " [  0   6   2   0   7   9   7   1  25  23   0 261  21   4   3   0   7   0\n",
      "   20   0]\n",
      " [  2  28   7  21  21   7  15   8  15  46   0   2 207   5   6   0   0   0\n",
      "    3   0]\n",
      " [ 13  34   0   1  11  13  15   2  37  35   2   1  60 152   2   5   0   1\n",
      "   10   2]\n",
      " [  5  15   0   0   2   1   3   2  22  36   1   0  19   2 266   0   5   0\n",
      "   14   1]\n",
      " [ 10  11   1   0   0   2   4   0  15  16   0   0  16   0   3 278   0   0\n",
      "    4  38]\n",
      " [  1   3   0   1   1   1   7   2  27  37   0   3   9   3   0   0 240   2\n",
      "   20   7]\n",
      " [ 17   6   0   0   1   0   7   2  15  52   2   0   5   0   0   3   3 241\n",
      "   17   5]\n",
      " [  2   4   0   0   2   1   4   0  16  21   1   1   8   1   8   1  67   0\n",
      "  171   2]\n",
      " [ 23   6   0   1   1   0   8   0  13  20   3   0   2   8   2  41  14   1\n",
      "   13  95]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.077s\n",
      "test time:  0.021s\n",
      "accuracy:   0.832\n",
      "dimensionality: 65536\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.84      0.78      0.81       319\n",
      "           comp.graphics       0.67      0.73      0.70       389\n",
      " comp.os.ms-windows.misc       0.70      0.68      0.69       394\n",
      "comp.sys.ibm.pc.hardware       0.65      0.75      0.69       392\n",
      "   comp.sys.mac.hardware       0.85      0.80      0.82       385\n",
      "          comp.windows.x       0.84      0.75      0.79       395\n",
      "            misc.forsale       0.80      0.82      0.81       390\n",
      "               rec.autos       0.88      0.90      0.89       396\n",
      "         rec.motorcycles       0.93      0.96      0.94       398\n",
      "      rec.sport.baseball       0.93      0.93      0.93       397\n",
      "        rec.sport.hockey       0.94      0.97      0.96       399\n",
      "               sci.crypt       0.92      0.93      0.92       396\n",
      "         sci.electronics       0.80      0.74      0.77       393\n",
      "                 sci.med       0.90      0.80      0.85       396\n",
      "               sci.space       0.88      0.92      0.90       394\n",
      "  soc.religion.christian       0.85      0.95      0.90       398\n",
      "      talk.politics.guns       0.74      0.91      0.82       364\n",
      "   talk.politics.mideast       0.96      0.94      0.95       376\n",
      "      talk.politics.misc       0.79      0.62      0.69       310\n",
      "      talk.religion.misc       0.76      0.61      0.67       251\n",
      "\n",
      "             avg / total       0.83      0.83      0.83      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[250   1   0   3   0   1   0   1   2   1   1   1   0   4   2  24   5   4\n",
      "    1  18]\n",
      " [  1 285  23  11   7  24   5   0   0   2   3   4  13   1   6   2   1   1\n",
      "    0   0]\n",
      " [  1  28 267  48   3  16   4   0   1   4   0   6   4   0   3   2   1   0\n",
      "    4   2]\n",
      " [  0  13  26 293  22   2   9   1   0   1   0   0  22   0   3   0   0   0\n",
      "    0   0]\n",
      " [  0   6  14  25 308   1  11   4   1   3   0   1   8   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0  49  24  10   4 298   2   1   1   0   0   0   0   2   4   0   0   0\n",
      "    0   0]\n",
      " [  0   4   7  23   5   0 319  11   4   1   3   0   7   4   1   0   1   0\n",
      "    0   0]\n",
      " [  0   2   1   4   0   0  13 357   7   1   1   0   4   2   1   0   2   0\n",
      "    1   0]\n",
      " [  0   0   0   1   0   0   5   6 381   1   0   0   3   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   4   4   0 368  13   0   0   0   4   0   2   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   2   0   0   0   3 389   1   0   1   1   1   0   0\n",
      "    1   0]\n",
      " [  1   5   2   1   2   3   4   3   0   0   0 368   2   1   0   0   3   0\n",
      "    1   0]\n",
      " [  1  10  12  28   6   2  10   5   7   0   0   8 292   7   3   0   0   1\n",
      "    1   0]\n",
      " [  2  12   2   2   2   2   9   8   2   3   0   2   9 318   4   4   1   2\n",
      "    9   3]\n",
      " [  1   5   2   2   1   4   0   0   0   3   0   0   2   4 363   1   3   0\n",
      "    3   0]\n",
      " [  2   1   1   1   0   0   0   0   1   1   1   0   0   3   1 378   1   0\n",
      "    1   6]\n",
      " [  0   0   0   1   2   0   1   1   0   1   0   4   0   1   1   0 333   1\n",
      "   10   8]\n",
      " [  3   1   0   0   0   1   0   0   1   0   1   0   0   0   0   3   2 352\n",
      "   11   1]\n",
      " [  4   4   0   0   1   0   0   2   1   0   1   4   0   2   8   1  77   3\n",
      "  192  10]\n",
      " [ 32   1   3   0   0   0   2   1   0   1   0   1   0   3   4  28  14   2\n",
      "    7 152]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.069s\n",
      "test time:  0.063s\n",
      "accuracy:   0.760\n",
      "dimensionality: 65536\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.76      0.80      0.78       319\n",
      "           comp.graphics       0.50      0.71      0.59       389\n",
      " comp.os.ms-windows.misc       0.75      0.13      0.22       394\n",
      "comp.sys.ibm.pc.hardware       0.52      0.74      0.61       392\n",
      "   comp.sys.mac.hardware       0.65      0.80      0.72       385\n",
      "          comp.windows.x       0.78      0.71      0.74       395\n",
      "            misc.forsale       0.56      0.87      0.68       390\n",
      "               rec.autos       0.87      0.86      0.86       396\n",
      "         rec.motorcycles       0.90      0.93      0.92       398\n",
      "      rec.sport.baseball       0.94      0.89      0.92       397\n",
      "        rec.sport.hockey       0.98      0.91      0.94       399\n",
      "               sci.crypt       0.85      0.84      0.85       396\n",
      "         sci.electronics       0.67      0.70      0.68       393\n",
      "                 sci.med       0.89      0.70      0.78       396\n",
      "               sci.space       0.87      0.81      0.84       394\n",
      "  soc.religion.christian       0.89      0.88      0.88       398\n",
      "      talk.politics.guns       0.81      0.84      0.82       364\n",
      "   talk.politics.mideast       0.97      0.82      0.89       376\n",
      "      talk.politics.misc       0.72      0.56      0.63       310\n",
      "      talk.religion.misc       0.70      0.65      0.67       251\n",
      "\n",
      "             avg / total       0.78      0.76      0.75      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[256   2   0   4   2   0   5   1   1   0   0   2   1   3   1  16   2   3\n",
      "    1  19]\n",
      " [  1 275   1  19  12  21  22   0   0   1   0   8  15   0  12   0   1   0\n",
      "    0   1]\n",
      " [  1  80  50 128  27  38  27   1   3   1   0  11  12   2   4   1   1   0\n",
      "    6   1]\n",
      " [  0  20   5 289  23   4  24   0   0   0   0   1  25   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0  13   3  23 308   0  10   2   1   0   0   3  16   1   4   0   0   0\n",
      "    1   0]\n",
      " [  0  67   3  15   7 279  10   1   0   0   0   4   7   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   4   1  19   7   1 341   6   1   0   0   0   4   3   2   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   4   5   0  27 340   7   0   0   1   6   1   0   0   0   0\n",
      "    4   0]\n",
      " [  0   0   0   2   1   0  10  10 370   0   0   1   2   0   0   0   0   0\n",
      "    2   0]\n",
      " [  1   0   0   2   5   1  12   0   1 354   9   0   3   1   2   0   1   0\n",
      "    5   0]\n",
      " [  1   1   2   0   4   0  12   0   3  10 362   0   0   0   0   0   0   0\n",
      "    4   0]\n",
      " [  1  10   0   7  11   2  13   3   0   0   0 333   5   1   3   0   3   1\n",
      "    3   0]\n",
      " [  1  16   1  24  14   3  22   1   4   0   0  19 276   7   4   0   0   0\n",
      "    1   0]\n",
      " [  3  15   0   4  16   1  23  14   4   2   0   0  21 277   1   2   1   2\n",
      "    8   2]\n",
      " [  4  17   0   5   5   3  17   2   0   2   0   0   9   6 318   0   0   0\n",
      "    6   0]\n",
      " [  3   6   0   2   4   2   7   0   4   2   0   0   4   1   0 349   0   1\n",
      "    1  12]\n",
      " [  0   1   0   2   5   1  10   6   3   0   0   4   1   1   1   0 306   0\n",
      "   12  11]\n",
      " [ 13  10   1   2   6   1   9   1   0   0   0   2   0   1   0   7   1 308\n",
      "   12   2]\n",
      " [ 14   5   0   0   5   1   3   4   7   1   0   2   4   2   8   0  58   0\n",
      "  174  22]\n",
      " [ 37   3   0   1   5   0   5   1   0   2   0   0   2   3   5  17   4   1\n",
      "    3 162]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomdr/VirtualEnvs/work-py3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 12.852s\n",
      "test time:  0.040s\n",
      "accuracy:   0.808\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.74      0.74      0.74       319\n",
      "           comp.graphics       0.70      0.75      0.72       389\n",
      " comp.os.ms-windows.misc       0.74      0.72      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.70      0.70      0.70       392\n",
      "   comp.sys.mac.hardware       0.77      0.79      0.78       385\n",
      "          comp.windows.x       0.83      0.72      0.77       395\n",
      "            misc.forsale       0.78      0.88      0.83       390\n",
      "               rec.autos       0.87      0.86      0.86       396\n",
      "         rec.motorcycles       0.92      0.92      0.92       398\n",
      "      rec.sport.baseball       0.88      0.89      0.88       397\n",
      "        rec.sport.hockey       0.92      0.95      0.94       399\n",
      "               sci.crypt       0.92      0.91      0.91       396\n",
      "         sci.electronics       0.70      0.71      0.70       393\n",
      "                 sci.med       0.85      0.82      0.83       396\n",
      "               sci.space       0.88      0.91      0.90       394\n",
      "  soc.religion.christian       0.81      0.91      0.86       398\n",
      "      talk.politics.guns       0.71      0.87      0.78       364\n",
      "   talk.politics.mideast       0.94      0.83      0.88       376\n",
      "      talk.politics.misc       0.76      0.58      0.66       310\n",
      "      talk.religion.misc       0.68      0.56      0.62       251\n",
      "\n",
      "             avg / total       0.81      0.81      0.81      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[235   2   0   1   0   0   2   0   3   2   0   2   3   7   6  26   0   5\n",
      "    2  23]\n",
      " [  1 290  13  10   7  24   4   5   1   5   3   3  11   3   5   1   0   1\n",
      "    1   1]\n",
      " [  0  23 284  34  12   8   4   3   1   5   0   3   4   3   4   0   1   0\n",
      "    1   4]\n",
      " [  0  14  26 276  21   4  17   2   0   2   0   1  26   0   0   0   2   0\n",
      "    1   0]\n",
      " [  2   7   2  20 305   1  20   0   0   2   2   1  15   4   0   1   3   0\n",
      "    0   0]\n",
      " [  1  41  38   7   6 283   2   0   0   2   1   0   5   3   3   0   1   1\n",
      "    1   0]\n",
      " [  0   2   2   8  11   0 342   7   1   2   1   2   6   2   1   2   0   0\n",
      "    1   0]\n",
      " [  1   2   2   3   2   1  10 339  10   1   0   2  16   3   0   1   1   0\n",
      "    2   0]\n",
      " [  1   0   1   2   0   0   4  10 368   3   0   0   2   0   1   1   3   0\n",
      "    1   1]\n",
      " [  3   0   0   1   2   1   5   1   1 353  20   0   2   1   1   1   4   0\n",
      "    1   0]\n",
      " [  0   0   0   0   5   1   2   0   4   4 381   0   0   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0   1   2   1   2   3   7   1   1   1   0 359   6   2   0   1   3   1\n",
      "    5   0]\n",
      " [  3  10   6  25  15   5  10   5   4   8   0   7 279   6   6   2   0   0\n",
      "    1   1]\n",
      " [  6   5   4   4   2   4   3   3   0   5   1   2   8 326   3   4   2   3\n",
      "    3   8]\n",
      " [  2   7   0   1   2   0   2   1   0   1   0   1   6   6 359   1   1   1\n",
      "    2   1]\n",
      " [ 12   1   3   0   0   1   0   1   1   1   0   0   3   1   2 361   0   0\n",
      "    0  11]\n",
      " [  1   2   1   3   1   0   3   1   1   3   0   4   1   7   0   1 316   2\n",
      "   11   6]\n",
      " [ 15   1   0   0   0   2   1   2   0   2   4   3   4   1   5   4   2 313\n",
      "   14   3]\n",
      " [  1   2   0   1   0   0   0   4   4   0   0   1   2   5   6   5  89   5\n",
      "  179   6]\n",
      " [ 34   3   1   0   1   1   1   3   0   1   0   0   0   5   4  32  14   2\n",
      "    8 141]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomdr/VirtualEnvs/work-py3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f784bbaa3de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# make some plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
